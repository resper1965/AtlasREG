# AtlasReg Scraper by ness.

**Sistema ConfigurÃ¡vel de Web Scraping para InteligÃªncia de Mercado**

---

## ğŸ¯ VisÃ£o Geral

Sistema de coleta automatizada de notÃ­cias e documentos do setor de transmissÃ£o de energia elÃ©trica brasileiro.

### Features

- âœ… **ConfigurÃ¡vel via YAML** - Adicionar fontes sem cÃ³digo
- âœ… **Multi-source** - 10+ fontes configuradas
- âœ… **Agendamento automÃ¡tico** - Airflow DAGs
- âœ… **Scraping Ã©tico** - Rate limiting, robots.txt
- âœ… **Retry logic** - 3 tentativas com backoff
- âœ… **Storage MinIO** - Documentos brutos salvos
- âœ… **Metadata PostgreSQL** - Tracking de documentos
- âœ… **Pipeline automÃ¡tico** - Dispara processamento IA

---

## ğŸ“ Estrutura

```
apps/scraper/
â”œâ”€â”€ config/
â”‚   â””â”€â”€ sources.yaml ............ ConfiguraÃ§Ã£o de todas as fontes
â”‚
â”œâ”€â”€ scrapers/
â”‚   â”œâ”€â”€ base_scraper.py ......... Spider configurÃ¡vel base
â”‚   â”œâ”€â”€ spider_factory.py ....... Factory de spiders
â”‚   â””â”€â”€ pipelines.py ............ MinIO + PostgreSQL pipelines
â”‚
â”œâ”€â”€ dags/
â”‚   â”œâ”€â”€ dynamic_scrapers_dag.py . Gerador automÃ¡tico de DAGs
â”‚   â””â”€â”€ aneel_daily_scraper.py .. DAG exemplo manual
â”‚
â”œâ”€â”€ processors/
â”‚   â”œâ”€â”€ pdf_processor.py ........ PDF to text (TODO)
â”‚   â”œâ”€â”€ classifier.py ........... BERTimbau (TODO)
â”‚   â””â”€â”€ entity_extractor.py ..... spaCy (TODO)
â”‚
â””â”€â”€ requirements.txt ............ Python dependencies
```

---

## ğŸ”§ ConfiguraÃ§Ã£o de Fontes (sources.yaml)

### Fontes Habilitadas (10)

**RegulatÃ³rias:**
1. âœ… **ANEEL NotÃ­cias** - DiÃ¡rio 06:00
2. âœ… **ANEEL Despachos** - DiÃ¡rio 07:00
3. âœ… **ANEEL PVs (Multas)** - Semanal (segundas 08:00)
4. âœ… **ONS OcorrÃªncias** - DiÃ¡rio 06:30

**Cadastrais:**
5. âœ… **SIGEL** - Mensal (dia 1, 09:00)

**MÃ­dia:**
6. âœ… **Canal Energia** - DiÃ¡rio 09:00
7. âœ… **MegaWhat** - DiÃ¡rio 09:30
8. âœ… **EPBR** - DiÃ¡rio 10:00

**Governo:**
9. âœ… **MME** - DiÃ¡rio 13:00
10. âœ… **EPE** - Semanal (segundas 00:00)

**Opcionais (Fase 2):**
- ABRATE (AssociaÃ§Ã£o)
- B3 Fatos Relevantes (API)
- CVM
- EstadÃ£o, Valor EconÃ´mico (paywall)

---

## ğŸš€ Como Adicionar Nova Fonte

### 1. Editar sources.yaml

```yaml
sources:
  - id: nova_fonte
    name: "Minha Fonte de NotÃ­cias"
    enabled: true
    priority: medium
    category: midia
    urls:
      base: "https://minhafonte.com.br"
      noticias: "https://minhafonte.com.br/noticias"
    scraper_type: scrapy
    schedule: "0 14 * * *"  # DiÃ¡rio 14:00
    selectors:
      lista: "article.noticia"
      titulo: "h2::text"
      url: "a::attr(href)"
      data: "time::attr(datetime)"
      resumo: "p.desc::text"
    filters:
      keywords:
        - transmissÃ£o
        - energia
    rate_limit: 5
```

### 2. Reiniciar Airflow

```bash
docker-compose restart airflow-scheduler
```

**Pronto!** DAG criado automaticamente.

---

## ğŸ•·ï¸ Como Funciona

### Sistema ConfigurÃ¡vel

```
1. sources.yaml
   â†“ (lido por)
2. spider_factory.py
   â†“ (cria)
3. ConfigurableSpider(source_id)
   â†“ (executa)
4. Scrapy crawl
   â†“ (salva via)
5. Pipelines â†’ MinIO + PostgreSQL
   â†“ (dispara)
6. Celery task â†’ Processamento IA
```

### Exemplo de ExecuÃ§Ã£o

```python
# Airflow dispara
python spider_factory.py aneel_noticias

# Spider carrega config
config = yaml.load('sources.yaml')
source = config['sources']['aneel_noticias']

# Visita URLs
response = scrapy.Request(source['urls']['noticias'])

# Extrai dados com selectors
items = response.css(source['selectors']['lista'])
titulo = item.css(source['selectors']['titulo']).get()

# Verifica filtros
if 'transmissÃ£o' in titulo:
    # Coleta!
    yield item

# Pipeline salva
MinIOPipeline.process_item(item)
PostgreSQLPipeline.process_item(item)
```

---

## ğŸ“Š Monitoramento

### Airflow UI

**URL:** http://localhost:8200  
**Login:** admin / admin

**Visualiza:**
```
DAGs:
â”œâ”€ scraper_aneel_noticias    âœ… Success (06:05) - 8 itens
â”œâ”€ scraper_aneel_despachos   âœ… Success (07:12) - 23 itens
â”œâ”€ scraper_ons_ocorrencias   âœ… Success (06:35) - 5 itens
â”œâ”€ scraper_canal_energia     âœ… Success (09:08) - 12 itens
â””â”€ scraper_megawhat          â³ Running (09:32)

Total hoje: 48 documentos coletados
```

### MinIO Console

**URL:** http://localhost:19001  
**Login:** admin / atlasreg2025

**Estrutura:**
```
raw-documents/
â”œâ”€â”€ aneel_noticias/
â”‚   â””â”€â”€ 2025-10-17/
â”‚       â”œâ”€â”€ aneel-aprova-reajuste-a1b2c3d4.json
â”‚       â”œâ”€â”€ nova-outorga-transmissora-x-e5f6g7h8.json
â”‚       â””â”€â”€ ...
â”œâ”€â”€ ons_ocorrencias/
â”‚   â””â”€â”€ 2025-10-17/
â”‚       â””â”€â”€ desligamento-lt-230kv-i9j0k1l2.json
â””â”€â”€ canal_energia/
    â””â”€â”€ 2025-10-17/
        â””â”€â”€ mercado-transmissao-m3n4o5p6.json
```

---

## ğŸ” Busca por Keywords

### Filtros ConfigurÃ¡veis

Cada source pode ter keywords para filtrar conteÃºdo:

```yaml
filters:
  keywords:
    - transmissÃ£o
    - transmissora
    - linhas de transmissÃ£o
    - subestaÃ§Ã£o
    - RAP
    - outorga
```

**LÃ³gica:**
- NotÃ­cia com "transmissÃ£o" no tÃ­tulo â†’ âœ… Coleta
- NotÃ­cia sobre geraÃ§Ã£o hidrelÃ©trica â†’ âŒ Ignora
- NotÃ­cia sobre "transmissora X recebe multa" â†’ âœ… Coleta

---

## â° Schedule AutomÃ¡tico

### Timeline DiÃ¡ria

```
06:00 â”€â–º ANEEL NotÃ­cias        (5-10 docs)
06:30 â”€â–º ONS OcorrÃªncias        (5-15 docs)
07:00 â”€â–º ANEEL Despachos        (20-50 docs)
08:00 â”€â–º ANEEL PVs (seg)        (10-20 docs/semana)
09:00 â”€â–º Canal Energia          (10-20 docs)
09:30 â”€â–º MegaWhat               (5-10 docs)
10:00 â”€â–º EPBR                   (5-10 docs)
12:00 â”€â–º ABRATE                 (5 docs)
13:00 â”€â–º MME                    (5-10 docs)

Total: ~60-135 docs/dia
```

### Schedule por Categoria

```yaml
# CrÃ­tico - mÃºltiplas vezes/dia
regulatorio: */6 * * * *     # A cada 6h

# Importante - diÃ¡rio
midia: 0 9 * * *             # Uma vez/dia manhÃ£

# Cadastral - periÃ³dico
cadastral: 0 9 1 * *         # Mensal

# Financeiro - tempo real (Fase 2)
financeiro: */30 * * * *     # A cada 30min
```

---

## ğŸ› ï¸ Comandos

### Testar Scraper Manualmente

```bash
# Rodar spider especÃ­fico
cd apps/scraper
scrapy crawl aneel_noticias

# Com output
scrapy crawl aneel_noticias -o output.json

# Apenas verificar (dry-run)
scrapy crawl aneel_noticias -s LOG_LEVEL=DEBUG
```

### Listar Spiders DisponÃ­veis

```bash
scrapy list
# Output:
# aneel_noticias
# aneel_despachos
# ons_ocorrencias
# canal_energia
# megawhat
# ...
```

### Verificar Config

```bash
# Validar YAML
python -c "import yaml; print(yaml.safe_load(open('config/sources.yaml')))"

# Listar sources habilitadas
python scrapers/spider_factory.py
```

---

## ğŸ“ˆ EstatÃ­sticas Esperadas

### Por MÃªs

- **Documentos coletados:** ~1,800-4,000
- **Eventos processados:** ~800-1,500 (apÃ³s filtros e dedup)
- **Multas detectadas:** ~30-50
- **DecisÃµes regulatÃ³rias:** ~100-200
- **TransaÃ§Ãµes M&A:** ~5-10
- **Incidentes operacionais:** ~150-300

### Storage

- **MinIO (raw):** ~500MB-1GB/mÃªs
- **PostgreSQL:** ~100-200MB/mÃªs (metadata)
- **Elasticsearch:** ~200-500MB/mÃªs (indexes)

---

## ğŸš¨ Tratamento de Erros

### Retry AutomÃ¡tico

```python
# Se scraper falha:
retry_times=3
retry_delay=5min (exponencial)

# Tentativa 1: Falha
# Aguarda 5min
# Tentativa 2: Falha
# Aguarda 10min
# Tentativa 3: Falha
# âŒ Marca como failed
# ğŸ“§ Email para admin
```

### Alertas

```yaml
# Configurado em sources.yaml
global_settings:
  alert_on_zero_results: true
  alert_on_errors: true
  alert_recipients:
    - admin@atlasreg.com
```

---

## âœ… PrÃ³ximos Passos

1. **Validar URLs** - Testar manualmente cada fonte
2. **Ajustar Selectors** - HTML real pode variar
3. **Implementar Playwright** - Para sites JS (ONS, Canal Energia)
4. **PDF Processing** - PDFMiner + OCR
5. **Celery Integration** - Disparar processamento
6. **Database Models** - Tabela documents completa

---

**Sistema configurÃ¡vel permite adicionar fontes em minutos! âš¡**

**Ver:** `/BUSCA_NOTICIAS_EXPLICADO.md` para detalhes tÃ©cnicos


