# ðŸŽ¯ Plano de FinalizaÃ§Ã£o - AtlasReg by ness.

**MÃ©todo:** BMad Structured Completion  
**Objetivo:** Sistema 100% funcional end-to-end  
**Timeline:** 6-8 semanas (acelerado)

---

## ðŸ“‹ FASE 1: VALIDAÃ‡ÃƒO E INTEGRAÃ‡ÃƒO SCRAPING (Semana 1-2)

### ðŸ•·ï¸ Epic 1.1: Validar Scrapers com URLs Reais

**Agente:** Developer + QA  
**Objetivo:** Testar e ajustar todos os 10 scrapers

**Tasks:**
1. [ ] Testar `aneel_noticias` scraper
   - Validar URL https://www.gov.br/aneel/pt-br/assuntos/noticias
   - Ajustar selectors se HTML mudou
   - Verificar rate limiting funciona
   - Testar filtros de keywords

2. [ ] Testar `aneel_despachos` scraper
   - Validar URLs de despachos
   - Implementar extraÃ§Ã£o de PDFs
   - Testar salvamento no MinIO

3. [ ] Testar `ons_ocorrencias` scraper
   - Implementar Playwright (site usa JS)
   - Validar extraÃ§Ã£o de dados tempo real
   - Testar parsing de datas

4. [ ] Testar `canal_energia` scraper
   - Implementar Playwright
   - Ajustar selectors para layout atual
   - Validar filtros funcionam

5. [ ] Testar `megawhat` scraper
6. [ ] Testar `epbr` scraper
7. [ ] Testar `mme` scraper
8. [ ] Testar `sigel` scraper
9. [ ] Testar `epe` scraper
10. [ ] Testar `aneel_pv` scraper

**CritÃ©rio de Sucesso:**
- âœ… 10/10 scrapers retornam dados vÃ¡lidos
- âœ… Dados salvos em MinIO corretamente
- âœ… Metadata registrada no PostgreSQL
- âœ… Zero erros em produÃ§Ã£o

---

### ðŸ¤– Epic 1.2: Integrar Pipeline de IA

**Agente:** Developer (IA/ML)  
**Objetivo:** Conectar scrapers â†’ IA â†’ eventos

**Tasks:**
1. [ ] Implementar Celery tasks
   ```python
   @celery.task
   def process_document(document_id):
       # Carregar documento
       # Classificar com BERTimbau
       # Extrair entidades com spaCy
       # Criar evento
       # Salvar embeddings
   ```

2. [ ] Integrar BERTimbau classifier
   - Download modelo: `neuralmind/bert-base-portuguese-cased`
   - Fine-tune para categorias do setor
   - Testar acurÃ¡cia (>85%)

3. [ ] Integrar spaCy entity extractor
   - Download modelo: `pt_core_news_lg`
   - Adicionar padrÃµes customizados (empresas, CNPJs)
   - Testar extraÃ§Ã£o

4. [ ] Implementar FAISS vector search
   - Criar Ã­ndice de embeddings
   - API endpoint para busca semÃ¢ntica
   - Testar queries

5. [ ] Pipeline completo end-to-end
   - Scraper coleta â†’ MinIO
   - Celery task dispara
   - IA processa
   - Event criado
   - Frontend atualiza

**CritÃ©rio de Sucesso:**
- âœ… Documentos classificados automaticamente (>85% acurÃ¡cia)
- âœ… Entidades extraÃ­das corretamente
- âœ… Eventos criados no banco
- âœ… Busca semÃ¢ntica funciona

---

### ðŸ³ Epic 1.3: Configurar Airflow Production

**Agente:** DevOps  
**Objetivo:** Airflow rodando com DAGs automÃ¡ticos

**Tasks:**
1. [ ] Adicionar Airflow ao docker-compose.yml
   ```yaml
   airflow-webserver:
     image: apache/airflow:2.7.3
     environment:
       - AIRFLOW__CORE__EXECUTOR=CeleryExecutor
   ```

2. [ ] Configurar volumes e persistÃªncia
3. [ ] Carregar DAGs dinamicamente
4. [ ] Configurar alertas (email/Slack)
5. [ ] Testar schedule automÃ¡tico

**CritÃ©rio de Sucesso:**
- âœ… Airflow UI acessÃ­vel (localhost:8200)
- âœ… 10 DAGs detectados automaticamente
- âœ… Schedule funcionando (cron)
- âœ… Alertas enviados em falhas

---

## ðŸ“‹ FASE 2: BACKEND FEATURES COMPLETAS (Semana 3-4)

### ðŸ”§ Epic 2.1: Implementar API Routes Completas

**Agente:** Backend Developer  
**Objetivo:** Todas as routes funcionando com dados reais

**Tasks:**
1. [ ] GET /events/search
   ```python
   @router.get("/events/search")
   async def search_events(
       query: Optional[str] = None,
       event_type: Optional[EventType] = None,
       company: Optional[str] = None,
       date_from: Optional[date] = None,
       date_to: Optional[date] = None,
       skip: int = 0,
       limit: int = 20
   ):
       # Buscar no banco com filtros
       # PaginaÃ§Ã£o
       # Retornar JSON
   ```

2. [ ] POST /watchlists
   ```python
   @router.post("/watchlists")
   async def create_watchlist(
       watchlist: WatchlistCreate,
       current_user: User = Depends(get_current_user)
   ):
       # Criar watchlist
       # Associar keywords/companies
       # Retornar watchlist_id
   ```

3. [ ] GET /events/feed
   ```python
   @router.get("/events/feed")
   async def get_feed(
       current_user: User = Depends(get_current_user)
   ):
       # Feed personalizado baseado em watchlists
       # Ordenar por relevÃ¢ncia
       # Marcar lidos/nÃ£o lidos
   ```

4. [ ] GET /companies/search
5. [ ] GET /companies/{id}/timeline
6. [ ] POST /alerts/configure
7. [ ] GET /documents/{id}
8. [ ] GET /analytics/dashboard

**CritÃ©rio de Sucesso:**
- âœ… Todas as 30+ rotas implementadas
- âœ… Swagger docs atualizado
- âœ… Testes unitÃ¡rios (>80% coverage)
- âœ… Performance <200ms

---

### ðŸ—„ï¸ Epic 2.2: Database Migrations e Seeds

**Agente:** Backend Developer  
**Objetivo:** Banco estruturado e populado

**Tasks:**
1. [ ] Criar migrations Alembic
   ```bash
   alembic revision --autogenerate -m "create_all_tables"
   alembic upgrade head
   ```

2. [ ] Seed inicial
   - 50+ empresas transmissoras (da ABRATE)
   - 10 usuÃ¡rios teste
   - Roles e permissÃµes

3. [ ] Ãndices otimizados
   - events.event_date
   - events.event_type
   - documents.source
   - documents.scraped_at

4. [ ] Views materializadas
   - dashboard_stats
   - top_companies
   - recent_events

**CritÃ©rio de Sucesso:**
- âœ… Banco criado automaticamente
- âœ… Seed data carregado
- âœ… Queries <100ms
- âœ… Backup automÃ¡tico configurado

---

## ðŸ“‹ FASE 3: FRONTEND FEATURES (Semana 5-6)

### ðŸŽ¨ Epic 3.1: Conectar Frontend ao Backend

**Agente:** Frontend Developer  
**Objetivo:** UI consumindo API real

**Tasks:**
1. [ ] Configurar API client
   ```typescript
   // lib/api.ts
   export const api = {
     events: {
       search: (params) => fetch('/api/events/search', params),
       getById: (id) => fetch(`/api/events/${id}`)
     }
   }
   ```

2. [ ] Implementar auth flow
   - Login chama POST /auth/login
   - Token salvo em cookies
   - Middleware protege rotas
   - Logout limpa sessÃ£o

3. [ ] TanStack Query setup
   ```typescript
   const { data: events } = useQuery({
     queryKey: ['events', filters],
     queryFn: () => api.events.search(filters)
   })
   ```

4. [ ] Estado global (Zustand)
   - User state
   - Filters state
   - Watchlists state

**CritÃ©rio de Sucesso:**
- âœ… Login funcional
- âœ… Dashboard mostra dados reais
- âœ… Loading states
- âœ… Error handling

---

### ðŸŽ¯ Epic 3.2: Implementar Features UI

**Agente:** Frontend Developer + UX  
**Objetivo:** Todas as telas funcionais

**Tasks:**
1. [ ] Events Feed Page
   - Lista de eventos
   - Filtros avanÃ§ados
   - PaginaÃ§Ã£o infinita
   - Card de evento expandÃ­vel

2. [ ] Events Search Page
   - Busca semÃ¢ntica
   - Filtros: tipo, empresa, data, valor
   - Resultados destacados
   - Export CSV/PDF

3. [ ] Watchlists Page
   - Criar/editar/deletar watchlists
   - Keywords management
   - Companies tracking
   - Alert settings

4. [ ] Company Profile Page
   - Dados cadastrais
   - Timeline de eventos
   - GrÃ¡fico RAP
   - Multas e decisÃµes

5. [ ] Dashboard Analytics
   - Cards de mÃ©tricas
   - Charts (Recharts)
   - Filtros por perÃ­odo
   - Export relatÃ³rios

6. [ ] Alerts Configuration
   - Email preferences
   - Notification types
   - Digest frequency
   - Test alert button

**CritÃ©rio de Sucesso:**
- âœ… Todas as 6 pÃ¡ginas funcionais
- âœ… UX fluida (transitions, loading)
- âœ… Responsivo (mobile-first)
- âœ… Acessibilidade WCAG AA

---

## ðŸ“‹ FASE 4: ALERTAS E NOTIFICAÃ‡Ã•ES (Semana 7)

### ðŸ“§ Epic 4.1: Sistema de Alertas

**Agente:** Backend Developer  
**Objetivo:** NotificaÃ§Ãµes automÃ¡ticas

**Tasks:**
1. [ ] Email templates (Jinja2)
   - Daily digest template
   - Alert template
   - Welcome email
   - Password reset

2. [ ] SMTP integration
   ```python
   from fastapi_mail import FastMail, MessageSchema
   
   async def send_alert(user, event):
       message = MessageSchema(
           subject=f"Alerta: {event.title}",
           recipients=[user.email],
           template_body={...}
       )
       await mail.send_message(message)
   ```

3. [ ] Celery tasks agendadas
   ```python
   @celery.task
   def send_daily_digest():
       for user in active_users:
           events = get_events_for_user(user)
           send_email(user, events)
   ```

4. [ ] In-app notifications
   - Table `notifications`
   - WebSocket real-time (opcional)
   - Notification bell UI

**CritÃ©rio de Sucesso:**
- âœ… Emails enviados diariamente
- âœ… Alertas instantÃ¢neos para eventos crÃ­ticos
- âœ… Taxa de entrega >95%
- âœ… Unsubscribe funcional

---

## ðŸ“‹ FASE 5: DEPLOY E MONITORING (Semana 8)

### ðŸš€ Epic 5.1: Deploy Production

**Agente:** DevOps  
**Objetivo:** Sistema rodando em VPS

**Tasks:**
1. [ ] Docker Compose produÃ§Ã£o
   ```yaml
   # docker-compose.prod.yml
   services:
     api:
       build: ./docker/Dockerfile.api
       restart: always
     web:
       build: ./docker/Dockerfile.web
       restart: always
     traefik:
       image: traefik:v2.10
       # SSL automÃ¡tico
   ```

2. [ ] Configurar Traefik + SSL
   - Let's Encrypt automÃ¡tico
   - Reverse proxy
   - Health checks

3. [ ] Environment variables
   - Secrets no `.env.production`
   - DATABASE_URL (Neon)
   - SMTP credentials
   - JWT_SECRET

4. [ ] CI/CD pipeline
   - GitHub Actions
   - Build on push
   - Deploy automÃ¡tico

**CritÃ©rio de Sucesso:**
- âœ… HTTPS funcionando
- âœ… Deploy automÃ¡tico
- âœ… Zero downtime
- âœ… Backups diÃ¡rios

---

### ðŸ“Š Epic 5.2: Monitoring e Observability

**Agente:** DevOps  
**Objetivo:** Monitoramento completo

**Tasks:**
1. [ ] Prometheus + Grafana
   ```yaml
   prometheus:
     image: prom/prometheus
   grafana:
     image: grafana/grafana
   ```

2. [ ] Dashboards
   - System metrics (CPU, RAM, disk)
   - Application metrics (requests/s, latency)
   - Scraping metrics (docs/day, errors)
   - Database metrics (queries, connections)

3. [ ] Alerting rules
   - CPU >80% â†’ alert
   - Scraper failed 3x â†’ alert
   - API latency >1s â†’ alert
   - Database down â†’ alert

4. [ ] Logs centralizados
   - Loki (opcional)
   - JSON structured logs
   - Query logs via Grafana

**CritÃ©rio de Sucesso:**
- âœ… Dashboards visÃ­veis
- âœ… Alertas funcionando
- âœ… Logs searchable
- âœ… Uptime >99.5%

---

## ðŸ“‹ FASE 6: TESTES E DOCUMENTAÃ‡ÃƒO (ContÃ­nuo)

### âœ… Epic 6.1: Testing

**Agente:** QA + Developer  
**Objetivo:** Coverage >80%

**Tasks:**
1. [ ] Testes unitÃ¡rios backend
   - pytest para API
   - Mock database
   - Coverage report

2. [ ] Testes integraÃ§Ã£o
   - Scraper â†’ Database
   - API â†’ Database
   - IA pipeline

3. [ ] Testes E2E frontend
   - Playwright/Cypress
   - User flows crÃ­ticos
   - Visual regression

4. [ ] Performance tests
   - Load testing (k6)
   - API stress test
   - Database optimization

**CritÃ©rio de Sucesso:**
- âœ… >80% coverage backend
- âœ… >70% coverage frontend
- âœ… E2E tests passando
- âœ… Performance benchmarks

---

### ðŸ“š Epic 6.2: DocumentaÃ§Ã£o Final

**Agente:** Tech Writer  
**Objetivo:** Docs completas para handoff

**Tasks:**
1. [ ] API Documentation
   - Swagger/OpenAPI completo
   - Exemplos de uso
   - Postman collection

2. [ ] User Manual
   - Como usar a plataforma
   - Screenshots
   - Video walkthrough

3. [ ] Admin Guide
   - Configurar scrapers
   - Gerenciar usuÃ¡rios
   - Troubleshooting

4. [ ] Developer Guide
   - Setup local
   - Arquitetura explicada
   - Como contribuir

**CritÃ©rio de Sucesso:**
- âœ… Docs atualizadas
- âœ… Videos gravados
- âœ… README completo
- âœ… Onboarding <30min

---

## ðŸ“ˆ TIMELINE E RECURSOS

### Semana 1-2: Scraping + IA
- **Agentes:** Dev Backend, Dev IA, DevOps
- **Entregas:** 10 scrapers validados, Pipeline IA, Airflow rodando

### Semana 3-4: Backend
- **Agentes:** Dev Backend, DBA
- **Entregas:** 30+ routes, Database completo

### Semana 5-6: Frontend
- **Agentes:** Dev Frontend, UX Designer
- **Entregas:** 6 pÃ¡ginas funcionais, UI polido

### Semana 7: Alertas
- **Agentes:** Dev Backend, Frontend
- **Entregas:** Email system, NotificaÃ§Ãµes

### Semana 8: Deploy
- **Agentes:** DevOps, SRE
- **Entregas:** ProduÃ§Ã£o, Monitoring

---

## ðŸŽ¯ DEFINITION OF DONE (DoD)

**Sistema 100% Funcional = Todos os itens âœ…:**

### Scraping
- [x] 10 fontes coletando dados diariamente
- [ ] Airflow schedulers rodando
- [ ] Dados salvos em MinIO
- [ ] Zero erros por 7 dias

### IA Pipeline
- [ ] Documentos classificados automaticamente
- [ ] Entidades extraÃ­das
- [ ] Eventos criados
- [ ] Busca semÃ¢ntica funcional

### Backend
- [ ] 30+ routes implementadas
- [ ] Auth JWT funcional
- [ ] Database otimizado
- [ ] API latency <200ms

### Frontend
- [ ] 6 pÃ¡ginas funcionais
- [ ] Dados reais exibidos
- [ ] UX fluida
- [ ] Mobile responsivo

### Alertas
- [ ] Emails diÃ¡rios enviados
- [ ] Alertas instantÃ¢neos
- [ ] In-app notifications

### Deploy
- [ ] HTTPS em produÃ§Ã£o
- [ ] SSL configurado
- [ ] Monitoring ativo
- [ ] Backups automÃ¡ticos

### Qualidade
- [ ] >80% test coverage
- [ ] Zero bugs crÃ­ticos
- [ ] DocumentaÃ§Ã£o completa
- [ ] Handoff realizado

---

## ðŸš€ EXECUÃ‡ÃƒO

**PrÃ³ximos Passos:**

1. **Agora:** Validar scrapers (Fase 1.1)
2. **Semana 1:** Pipeline IA (Fase 1.2)
3. **Semana 2:** Airflow + Backend routes (Fase 1.3 + 2.1)
4. **Semanas 3-4:** Backend completo (Fase 2)
5. **Semanas 5-6:** Frontend (Fase 3)
6. **Semana 7:** Alertas (Fase 4)
7. **Semana 8:** Deploy (Fase 5)

**Total:** 8 semanas estruturadas com BMad Method

---

**Status:** âœ… PLANO APROVADO PARA EXECUÃ‡ÃƒO

**Ver tambÃ©m:**
- `/IMPLEMENTACAO_FINAL.md` - Estado atual
- `/docs/prd.md` - 34 user stories
- `/docs/fullstack-architecture.md` - Arquitetura C4


