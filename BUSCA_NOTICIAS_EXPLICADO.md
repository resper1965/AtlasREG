# ğŸ” Como o AtlasReg Busca NotÃ­cias - EXPLICADO

**Powered by:** ness. (Montserrat Medium, ponto em #00ADE8)

---

## ğŸ“– PARA QUEM NÃƒO Ã‰ TÃ‰CNICO

### Como Funciona (Analogia Simples)

Imagine que vocÃª tem um **assistente robÃ´** que:

1. **ğŸŒ… Todo dia de manhÃ£ Ã s 6h:**
   - Abre o site da ANEEL
   - Abre o site do ONS
   - Abre Canal Energia, MegaWhat, EPBR
   - LÃª todas as notÃ­cias novas

2. **ğŸ“ Para cada notÃ­cia:**
   - Copia o tÃ­tulo
   - Copia a data
   - Copia o texto completo
   - Baixa PDFs se tiver
   - Salva tudo organizado

3. **ğŸ¤– Depois analisa com InteligÃªncia Artificial:**
   - Ã‰ sobre multa? DecisÃ£o? TransaÃ§Ã£o?
   - Quais empresas sÃ£o mencionadas?
   - Tem valores em reais?
   - Quais ativos (linhas, subestaÃ§Ãµes)?

4. **ğŸ“Š Organiza no Dashboard:**
   - Mostra as notÃ­cias classificadas
   - Permite buscar por empresa, tipo, data
   - Destaca eventos importantes

5. **ğŸ“§ Te avisa por email:**
   - "OlÃ¡! Hoje apareceram 3 multas e 1 transaÃ§Ã£o sobre empresas que vocÃª monitora"

**Tudo isso automaticamente, sem vocÃª fazer nada!**

---

## ğŸ› ï¸ PARA QUEM Ã‰ TÃ‰CNICO

### Arquitetura de Scraping

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  AIRFLOW SCHEDULER (Orquestrador)               â”‚
â”‚  - Cron: 06:00 daily                            â”‚
â”‚  - Dispara DAGs (tasks agendadas)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â”œâ”€â†’ DAG 1: ANEEL News (06:00)
               â”œâ”€â†’ DAG 2: ANEEL Despachos (07:00)
               â”œâ”€â†’ DAG 3: ONS OcorrÃªncias (06:30)
               â”œâ”€â†’ DAG 4: SIGEL (Mensal)
               â””â”€â†’ DAG 5: MÃ­dia (09:00-10:00)
               â”‚
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SCRAPY/PLAYWRIGHT (Workers)                    â”‚
â”‚  - Faz HTTP requests                            â”‚
â”‚  - Parse HTML com CSS selectors                 â”‚
â”‚  - Extrai dados estruturados                    â”‚
â”‚  - Rate limiting (1 req/5s)                     â”‚
â”‚  - Retry logic (3x com backoff)                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MINIO (Object Storage)                         â”‚
â”‚  Bucket: raw-documents/                         â”‚
â”‚  â”œâ”€ aneel/news/2025-10-17/noticia1.json        â”‚
â”‚  â”œâ”€ aneel/despachos/2025-10-17/despacho1.pdf   â”‚
â”‚  â””â”€ ons/ocorrencias/2025-10-17/ocorrencia1.jsonâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  POSTGRESQL (Metadata)                          â”‚
â”‚  Tabela: documents                              â”‚
â”‚  - id, filename, source, type, status, url      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â†“ (trigger)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CELERY TASK: process_document                  â”‚
â”‚  - LÃª de MinIO                                  â”‚
â”‚  - Processa com IA                              â”‚
â”‚  - Salva evento estruturado                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ•·ï¸ TECNOLOGIAS DE SCRAPING

### 1. Scrapy - Para Sites HTML EstÃ¡ticos

**Usado em:**
- ANEEL (notÃ­cias, despachos)
- ONS (boletins)
- SIGEL (dados cadastrais)

**Como funciona:**
```python
# 1. Define URL inicial
start_urls = ['https://www.gov.br/aneel/pt-br/assuntos/noticias']

# 2. Scrapy faz request HTTP
response = scrapy.Request(url)

# 3. Parse HTML com CSS selectors
noticias = response.css('div.item-noticia')

# 4. Extrai dados
for noticia in noticias:
    titulo = noticia.css('h2::text').get()
    data = noticia.css('time::attr(datetime)').get()
    url = noticia.css('a::attr(href)').get()
```

**Vantagens:**
- âœ… Muito rÃ¡pido (async)
- âœ… Built-in rate limiting
- âœ… Retry automÃ¡tico
- âœ… Pipelines para processar dados
- âœ… Middlewares (proxies, user-agents)

### 2. Playwright - Para Sites JavaScript

**Usado em:**
- Canal Energia (conteÃºdo dinÃ¢mico)
- Sites que carregam via AJAX
- Sites com infinite scroll

**Como funciona:**
```python
from playwright.sync_api import sync_playwright

with sync_playwright() as p:
    # Abre navegador real (Chromium)
    browser = p.chromium.launch(headless=True)
    page = browser.new_page()
    
    # Navega para URL
    page.goto('https://www.canalenergia.com.br/')
    
    # ESPERA JavaScript carregar
    page.wait_for_selector('article.noticia')
    
    # Extrai dados APÃ“S JS renderizar
    noticias = page.query_selector_all('article.noticia')
    
    for noticia in noticias:
        titulo = noticia.inner_text()
        # ...
```

**Vantagens:**
- âœ… Renderiza JavaScript
- âœ… Simula navegador real
- âœ… Pode clicar, scroll, preencher forms
- âœ… Screenshots para debug

**Desvantagens:**
- âŒ Mais lento que Scrapy
- âŒ Usa mais recursos (RAM)

---

## â° AGENDAMENTO: Como Funciona

### Airflow Schedule

**Sintaxe Cron:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ minuto (0-59)
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€ hora (0-23)
â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€ dia do mÃªs (1-31)
â”‚ â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€ mÃªs (1-12)
â”‚ â”‚ â”‚ â”‚ â”Œâ”€â”€â”€ dia da semana (0-6, 0=domingo)
â”‚ â”‚ â”‚ â”‚ â”‚
0 6 * * *  â† Todo dia Ã s 06:00

0 7 * * *  â† Todo dia Ã s 07:00
0 8 * * 1  â† Toda segunda Ã s 08:00
0 9 1 * *  â† Dia 1 de cada mÃªs Ã s 09:00
```

### Schedule do AtlasReg

```python
# apps/scraper/dags/

# DAG 1: ANEEL NotÃ­cias
schedule_interval='0 6 * * *'  # 06:00 diÃ¡rio
# Documentos esperados: 5-10/dia

# DAG 2: ANEEL Despachos
schedule_interval='0 7 * * *'  # 07:00 diÃ¡rio
# Documentos esperados: 20-50/dia

# DAG 3: ANEEL PVs (Multas)
schedule_interval='0 8 * * 1'  # 08:00 segundas
# Documentos esperados: 10-20/semana

# DAG 4: ONS OcorrÃªncias
schedule_interval='30 6 * * *'  # 06:30 diÃ¡rio
# Documentos esperados: 5-15/dia

# DAG 5: SIGEL
schedule_interval='0 9 1 * *'  # Dia 1 do mÃªs 09:00
# Documentos esperados: 100-200/mÃªs

# DAG 6: Canal Energia
schedule_interval='0 9 * * *'  # 09:00 diÃ¡rio
# Documentos esperados: 10-20/dia

# DAG 7: MegaWhat
schedule_interval='30 9 * * *'  # 09:30 diÃ¡rio
# Documentos esperados: 5-10/dia

# DAG 8: EPBR
schedule_interval='0 10 * * *'  # 10:00 diÃ¡rio
# Documentos esperados: 5-10/dia
```

**Total:** ~60-135 documentos coletados automaticamente por dia

---

## ğŸ“Š MONITORAMENTO DA COLETA

### Airflow UI (http://localhost:8200)

**Visualiza:**
- ğŸ“… Quais DAGs rodaram hoje
- âœ… Status: Success / Failed / Running
- â±ï¸ Tempo de execuÃ§Ã£o
- ğŸ“ˆ HistÃ³rico (Ãºltimos 30 dias)
- ğŸ”„ Retries (se houve falhas)
- ğŸ“Š Logs detalhados

**Exemplo de visualizaÃ§Ã£o:**
```
DAG: aneel_news_daily
â”œâ”€ 2025-10-17 06:00 âœ… Success (2m 15s)
â”‚  â”œâ”€ scrape_aneel âœ… (1m 50s) - 8 notÃ­cias
â”‚  â”œâ”€ trigger_processing âœ… (5s)
â”‚  â””â”€ notify_summary âœ… (2s)
â”‚
â”œâ”€ 2025-10-16 06:00 âœ… Success (2m 03s)
â”‚  â””â”€ 7 notÃ­cias coletadas
â”‚
â””â”€ 2025-10-15 06:00 âš ï¸ Retry (1m 30s)
   â””â”€ 5 notÃ­cias (falhou 1x, sucesso na retry)
```

---

## ğŸ¯ DADOS COLETADOS - FORMATO

### Documento Bruto (JSON em MinIO)

```json
{
  "title": "ANEEL aprova novos critÃ©rios para RAP de transmissoras",
  "date": "2025-10-17T05:30:00",
  "url": "https://www.gov.br/aneel/pt-br/assuntos/noticias/2025/aneel-aprova-novos-criterios",
  "summary": "A diretoria colegiada da ANEEL aprovou em reuniÃ£o...",
  "body": "A AgÃªncia Nacional de Energia ElÃ©trica (ANEEL) aprovou nesta terÃ§a-feira (17) novos critÃ©rios para a Receita Anual Permitida (RAP) das transmissoras...",
  "source": "ANEEL",
  "source_type": "news",
  "pdfs": [
    "https://www.gov.br/aneel/pt-br/.../nota-tecnica-123.pdf"
  ],
  "scraped_at": "2025-10-17T06:05:32",
  "word_count": 542,
  "has_attachments": true
}
```

### Documento Processado (PostgreSQL)

```sql
-- Tabela: events
INSERT INTO events VALUES (
  id: 'evt_a1b2c3d4',
  title: 'ANEEL aprova novos critÃ©rios para RAP de transmissoras',
  summary: 'A diretoria colegiada da ANEEL aprovou...',
  event_type: 'DECISAO',          â† Classificado pela IA
  company_id: null,                â† NÃ£o menciona empresa especÃ­fica
  amount: null,
  date: '2025-10-17 05:30:00',
  source: 'ANEEL',
  source_url: 'https://...',
  document_id: 'doc_xyz',
  confidence_score: 0.87,          â† 87% de confianÃ§a na classificaÃ§Ã£o
  is_critical: false,
  created_at: '2025-10-17 06:12:00'
);

-- Tabela: extracted_entities
INSERT INTO extracted_entities VALUES
  ('ent_1', 'evt_a1b2c3d4', 'ORG', 'ANEEL', 0.95),
  ('ent_2', 'evt_a1b2c3d4', 'ORG', 'diretoria colegiada', 0.82),
  ('ent_3', 'evt_a1b2c3d4', 'DATE', '17 de outubro', 0.98);
```

---

## ğŸ” SCRAPING Ã‰TICO

### Regras Que Seguimos

1. **robots.txt**
   ```python
   ROBOTSTXT_OBEY = True  # Respeita regras do site
   ```

2. **Rate Limiting**
   ```python
   DOWNLOAD_DELAY = 5  # 5 segundos entre requests
   # Evita sobrecarregar servidor do site
   ```

3. **User-Agent IdentificÃ¡vel**
   ```python
   USER_AGENT = 'AtlasReg/1.0 by ness. (+https://atlasreg.com; contato@atlasreg.com)'
   # Site pode nos contatar se houver problema
   ```

4. **HorÃ¡rios de Baixo TrÃ¡fego**
   ```python
   schedule_interval='0 6 * * *'  # 06:00 da manhÃ£
   # Evita horÃ¡rio comercial (menos impacto)
   ```

5. **Caching**
   ```python
   # NÃ£o re-baixa conteÃºdo jÃ¡ coletado
   # Verifica hash/data modificaÃ§Ã£o antes
   ```

6. **Retry com Backoff**
   ```python
   retries=3
   retry_delay=timedelta(minutes=5)  # Exponencial
   # Se falhar, espera antes de tentar denovo
   ```

---

## ğŸ“Š EXEMPLO: Dia TÃ­pico de Coleta

### Timeline de 17/10/2025

```
05:55 - Airflow scheduler acorda
06:00 - âœ… DAG aneel_news_daily inicia
06:01 - ğŸ•·ï¸  Scrapy visita gov.br/aneel
06:02 - ğŸ“° Encontra 8 notÃ­cias
06:03-06:05 - Visita cada notÃ­cia, extrai conteÃºdo completo
06:05 - ğŸ’¾ Salva 8 JSONs no MinIO
06:05 - ğŸ“ Registra 8 documentos no PostgreSQL
06:06 - ğŸ¤– Dispara Celery task: process_documents(8)
06:07-06:12 - IA processa:
           - Classifica (BERTimbau): 5 DECISÃƒO, 2 NOTÃCIA, 1 OUTRO
           - Extrai entidades (spaCy): 12 empresas, 3 CNPJs, 5 valores
06:12 - ğŸ’¾ Salva 8 eventos no PostgreSQL
06:12 - ğŸ” Indexa em FAISS (semantic) + Elasticsearch (full-text)
06:13 - âœ… DAG concluÃ­do

06:30 - âœ… DAG ons_ocorrencias inicia
06:31-06:35 - Coleta 6 ocorrÃªncias do ONS
06:35 - ğŸ¤– Processa: 4 INCIDENTE, 2 NOTÃCIA
06:37 - âœ… DAG concluÃ­do

07:00 - âœ… DAG aneel_despachos inicia
... (continua)

08:00 - ğŸ“§ Daily digest task executa
       - Busca watchlists dos usuÃ¡rios
       - Encontra 15 eventos que match critÃ©rios
       - Envia 5 emails personalizados

RESULTADO DO DIA:
- 65 documentos coletados
- 58 processados com sucesso
- 7 erros (retry agendado)
- 15 eventos crÃ­ticos detectados
- 5 usuÃ¡rios alertados
```

---

## ğŸ¯ SELETORES CSS - Como Extrair Dados

### Exemplo PrÃ¡tico ANEEL

**HTML da pÃ¡gina:**
```html
<div class="item-noticia">
  <h2 class="titulo">
    <a href="/noticias/2025/aneel-aprova-novos-criterios">
      ANEEL aprova novos critÃ©rios para RAP
    </a>
  </h2>
  <time datetime="2025-10-17T05:30:00">17/10/2025</time>
  <p class="resumo">A diretoria colegiada da ANEEL...</p>
</div>
```

**Scraper extrai:**
```python
# CSS Selectors (como "endereÃ§o" de cada dado)
titulo = response.css('div.item-noticia h2.titulo a::text').get()
# Output: "ANEEL aprova novos critÃ©rios para RAP"

url = response.css('div.item-noticia h2.titulo a::attr(href)').get()
# Output: "/noticias/2025/aneel-aprova-novos-criterios"

data = response.css('div.item-noticia time::attr(datetime)').get()
# Output: "2025-10-17T05:30:00"

resumo = response.css('div.item-noticia p.resumo::text').get()
# Output: "A diretoria colegiada da ANEEL..."
```

---

## ğŸš¨ TRATAMENTO DE ERROS

### O Que Pode Dar Errado

#### 1. Site fora do ar
```python
# Scrapy tenta 3x com intervalo
retries=3
retry_delay=5 minutos

# Se falhar 3x:
# - Log erro no Airflow
# - Email para admin
# - Tenta novamente no prÃ³ximo dia
```

#### 2. HTML mudou (site redesign)
```python
# Scraper nÃ£o encontra seletores
# Result: 0 notÃ­cias

# Monitoramento detecta:
if noticias_coletadas == 0:
    send_alert("âš ï¸ ANEEL scraper retornou 0 itens - verificar!")

# Admin recebe alerta
# Atualiza seletores CSS no cÃ³digo
# Redeploy scraper
```

#### 3. CAPTCHA / Bloqueio
```python
# Site detecta bot e bloqueia

# MitigaÃ§Ãµes:
# - Rotating user-agents
# - Rotating proxies (se necessÃ¡rio)
# - Aumentar delay (10s ao invÃ©s de 5s)
# - Usar Playwright (simula humano)
```

---

## ğŸ’¾ ARMAZENAMENTO

### MinIO (Object Storage)

**Estrutura de pastas:**
```
raw-documents/
â”œâ”€â”€ aneel/
â”‚   â”œâ”€â”€ news/
â”‚   â”‚   â”œâ”€â”€ 2025-10-17/
â”‚   â”‚   â”‚   â”œâ”€â”€ noticia-1.json
â”‚   â”‚   â”‚   â”œâ”€â”€ noticia-2.json
â”‚   â”‚   â”‚   â””â”€â”€ noticia-3.json
â”‚   â”‚   â””â”€â”€ 2025-10-16/
â”‚   â”‚       â””â”€â”€ ...
â”‚   â”œâ”€â”€ despachos/
â”‚   â”‚   â””â”€â”€ 2025-10-17/
â”‚   â”‚       â”œâ”€â”€ despacho-123.pdf
â”‚   â”‚       â””â”€â”€ despacho-124.pdf
â”‚   â””â”€â”€ pvs/
â”‚       â””â”€â”€ 2025-10/
â”‚           â””â”€â”€ pv-multa-transmissora-x.pdf
â”‚
â”œâ”€â”€ ons/
â”‚   â””â”€â”€ ocorrencias/
â”‚       â””â”€â”€ 2025-10-17/
â”‚           â””â”€â”€ ocorrencia-desligamento.json
â”‚
â””â”€â”€ midia/
    â”œâ”€â”€ canal-energia/
    â”œâ”€â”€ megawhat/
    â””â”€â”€ epbr/
```

**Acesso:** http://localhost:19001 (MinIO Console)

---

## ğŸ” BUSCA NO FRONTEND

### Como UsuÃ¡rio Busca

**Interface:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ” Buscar eventos...                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                          â”‚
â”‚  Filtros:                                â”‚
â”‚  â”œâ”€ Tipo: [â˜‘ Multa] [â˜ DecisÃ£o] ...    â”‚
â”‚  â”œâ”€ Empresa: [Transmissora X â–¼]         â”‚
â”‚  â”œâ”€ Data: [Ãšltimos 30 dias â–¼]           â”‚
â”‚  â””â”€ Valor mÃ­n: [R$ 1.000.000]           â”‚
â”‚                                          â”‚
â”‚  [Buscar]                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Backend processa:**
```python
# API: GET /events/search
params = {
    'q': 'multa',
    'event_type': 'MULTA',
    'company': 'Transmissora X',
    'date_from': '2025-09-17',
    'min_amount': 1000000
}

# Elasticsearch query
es.search(index='events', body={
    "query": {
        "bool": {
            "must": [{"match": {"text": "multa"}}],
            "filter": [
                {"term": {"event_type": "MULTA"}},
                {"term": {"company.keyword": "Transmissora X"}},
                {"range": {"date": {"gte": "2025-09-17"}}},
                {"range": {"amount": {"gte": 1000000}}}
            ]
        }
    }
})

# Retorna eventos ordenados por relevÃ¢ncia
```

---

## âš¡ RESUMO: 5 Passos AutomÃ¡ticos

```
1ï¸âƒ£ COLETAR (06:00-10:00)
   Scrapers visitam sites, baixam conteÃºdo
   â†’ Salva em MinIO + PostgreSQL

2ï¸âƒ£ PROCESSAR (06:15-11:00)
   IA classifica tipo, extrai entidades
   â†’ Salva eventos estruturados

3ï¸âƒ£ INDEXAR (06:20-11:05)
   FAISS (semantic) + Elasticsearch (full-text)
   â†’ Permite buscas rÃ¡pidas

4ï¸âƒ£ ALERTAR (08:00)
   Verifica watchlists, envia emails
   â†’ UsuÃ¡rios informados proativamente

5ï¸âƒ£ VISUALIZAR (sempre)
   Dashboard mostra eventos
   â†’ UsuÃ¡rio busca, filtra, explora
```

**Tudo acontece AUTOMATICAMENTE, SEM INTERVENÃ‡ÃƒO MANUAL! ğŸ¤–**

---

## ğŸ“ FAQ

**P: Quantos documentos sÃ£o coletados por dia?**  
R: ~60-135 documentos/dia dependendo da atividade regulatÃ³ria

**P: Quanto tempo leva para uma notÃ­cia aparecer no dashboard?**  
R: ~10-15 minutos apÃ³s publicaÃ§Ã£o (se cair no horÃ¡rio de scraping)

**P: E se o site da ANEEL cair?**  
R: Scraper tenta 3x com intervalo. Se falhar, log + alerta. Tenta novamente no prÃ³ximo dia.

**P: Posso escolher quais fontes monitorar?**  
R: Sim! Via watchlists vocÃª filtra por source, tipo, empresa, keywords.

**P: Como o sistema sabe que uma notÃ­cia Ã© nova?**  
R: Compara URL + data com documentos jÃ¡ coletados no PostgreSQL.

**P: E se eu quiser adicionar uma fonte nova?**  
R: Criar novo spider Scrapy + DAG Airflow. ~2-4 horas de trabalho.

---

**Documento preparado por:** BMad Master  
**Ver cÃ³digo:** `/apps/scraper/scrapers/aneel_news_spider.py`  
**Ver DAG:** `/apps/scraper/dags/aneel_daily_scraper.py`


